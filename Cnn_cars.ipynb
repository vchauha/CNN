{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code to download data from CIFAR-10 \n",
    "train_dataset= dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracting images of car from the entire dataset\n",
    "cars=[]\n",
    "\n",
    "for i in range(0,len(train_dataset.train_labels)):\n",
    "    if train_dataset[i][1] == 1 :\n",
    "        cars.append(train_dataset[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#display each image - data labelling\n",
    "to_img = ToPILImage()\n",
    "data= to_img(cars[1500][0])\n",
    "#data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data is created by storing each car type in the csv file\n",
    "f = open('Data_Project_DL.csv', 'a')\n",
    "#f.write('Hatchback')\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"Data_Project_DL.csv\", header=None)\n",
    "data= np.array(data)\n",
    "sedanIndex = []\n",
    "sedanImages = []\n",
    "hatchIndex = []\n",
    "hatchImages = []\n",
    "suvIndex = []\n",
    "suvImages = []\n",
    "conIndex = []\n",
    "conImages = []\n",
    "commonLabels = []\n",
    "commonImages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "countSedan = 0\n",
    "countSUV = 0\n",
    "countHatch = 0\n",
    "countCon = 0\n",
    "for i in range(0, len(data)):\n",
    "    if data[i]== 'Sedan':\n",
    "        data[i]= 1\n",
    "        sedanIndex.append(i)\n",
    "        #sedanImages.append(cars[i][0])\n",
    "        if countSedan <= 154:\n",
    "            # np.insert(commonLabels, data[i])\n",
    "           # print(data[i])\n",
    "            commonLabels.append(1)\n",
    "            commonImages.append(cars[i][0])\n",
    "            countSedan +=1\n",
    "    elif data[i]== 'SUV':\n",
    "        data[i]= 2\n",
    "        suvIndex.append(i)\n",
    "        #suvImages.append(cars[i][0])\n",
    "        if countSUV <= 154:\n",
    "            commonLabels.append(2)\n",
    "            commonImages.append(cars[i][0])\n",
    "            countSUV +=1\n",
    "    elif data[i]== 'Hatchback':\n",
    "        data[i]= 2\n",
    "        hatchIndex.append(i)\n",
    "        #hatchImages.append(cars[i][0])\n",
    "        if countHatch <= 154:\n",
    "            commonLabels.append(3)\n",
    "            commonImages.append(cars[i][0])\n",
    "            countHatch +=1\n",
    "    elif data[i]== 'Convertible':\n",
    "        data[i]= 2\n",
    "        conIndex.append(i)\n",
    "        #conImages.append(cars[i][0])\n",
    "        if countCon <= 154:\n",
    "            commonLabels.append(4)\n",
    "            commonImages.append(cars[i][0])\n",
    "            countCon +=1\n",
    "#print(\"Sedan count:\"+ str(len(sedanIndex)))\n",
    "#print(\"suv count:\"+ str(len(suvIndex)))\n",
    "#print(\"hatchback count:\"+ str(len(hatchIndex)))\n",
    "#print(\"convertible count:\"+ str(len(conIndex)))\n",
    "#print(\"Total labels in commonlist:\" + str(len(commonLabels)))\n",
    "#print(\"total images in common:\"+ str(len(commonImages)))\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commonLabels= pd.DataFrame(commonLabels)\n",
    "commonLabels= np.array(commonLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separating training, validation and test data from created dataset\n",
    "X_train= cars[0:1200][0][0].numpy().reshape(1, 32, 32, 3)\n",
    "X_val= cars[1201:1501][0][0].numpy().reshape(1, 32, 32, 3)\n",
    "#X_test= commonImages[1202:1501][0][0]\n",
    "Y_train= data[0:1200]\n",
    "#Y_train= np.array(Y_train).reshape(1200,1)\n",
    "#Y_train = keras.utils.to_categorical(np.ravel(Y_train))\n",
    "Y_val= data[1201:1501]\n",
    "#Y_val = keras.utils.to_categorical(np.ravel(Y_val))\n",
    "#Y_val= np.array(Y_val).reshape(300,1)\n",
    "# Y_test= data[1202:1501]\n",
    "# Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(0, len(Y_train)):\n",
    "#     if  Y_train[i]=='Sedan':\n",
    "#         Y_train[i]=1\n",
    "#     if  Y_train[i]=='SUV':\n",
    "#         Y_train[i]=2\n",
    "#     if  Y_train[i]=='Hatchback':\n",
    "#         Y_train[i]=3\n",
    "#     if  Y_train[i]=='Convertible':\n",
    "#         Y_train[i]=4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1= []\n",
    "for i in range(0, 1200):\n",
    "    X_train_1.append(np.array(cars[i][0].numpy().reshape(1, 32, 32, 3)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_2  = np.array(X_train_1).reshape(1200,32,32,3)\n",
    "print(X_train_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val_1= []\n",
    "for i in range(1201, 1501):\n",
    "    X_val_1.append(np.array(cars[i][0].numpy().reshape(1,32, 32, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val_2= np.array(X_val_1).reshape(300,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train = X_train_1.reshape(X_train_1.shape[0], 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1= X_train.astype('float32')\n",
    "X_val_1= X_val.astype('float32')\n",
    "X_train_1 /= 255\n",
    "X_val_1 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GaussianNoise\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vicky\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  import sys\n",
      "C:\\Users\\Vicky\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Vicky\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Vicky\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "C:\\Users\\Vicky\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n"
     ]
    }
   ],
   "source": [
    "#Initialize CNN\n",
    "\n",
    "\n",
    "classifier= Sequential()\n",
    "\n",
    "#First Convolutional Layer\n",
    "classifier.add(Convolution2D(512, 3, 3 , input_shape= (32, 32, 3), activation='relu'))\n",
    "\n",
    "\n",
    "#Max Pool\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "\n",
    "classifier.add(Convolution2D(1024, 3, 3, activation= 'relu'))\n",
    "\n",
    "#Max pool\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "\n",
    "classifier.add(Dropout(0.15))\n",
    "#Third Conv\n",
    "\n",
    "classifier.add(Convolution2D(2048, 3, 3, activation= 'relu'))\n",
    "\n",
    "#Third Maxpool\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "classifier.add(Dropout(0.10))\n",
    "#Flatten\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Hidden_layer\n",
    "\n",
    "classifier.add(Dense(output_dim=128, activation = 'relu'))\n",
    "classifier.add(GaussianNoise(0.25))\n",
    "classifier.add(BatchNormalization())\n",
    "# classifier.add(Dense(output_dim=128, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=128, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(GaussianNoise(0.25))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(GaussianNoise(0.25))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(GaussianNoise(0.25))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "# # classifier.add(GaussianNoise(0.25))\n",
    "\n",
    "#Outer_layer\n",
    "\n",
    "classifier.add(Dense(output_dim=1, activation = 'sigmoid'))\n",
    "\n",
    "#Compile\n",
    "\n",
    "from keras import optimizers\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "opt = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "classifier.compile(optimizer= opt , loss= 'binary_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "#Image Augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,                         \n",
    "        samplewise_center=False,                         \n",
    "        featurewise_std_normalization=False,                         \n",
    "        samplewise_std_normalization=True,                  \n",
    "        zca_whitening=False,                         \n",
    "        rotation_range=0,                         \n",
    "        width_shift_range=0.1,                         \n",
    "        height_shift_range=0.1,                         \n",
    "        horizontal_flip=True,                         \n",
    "        vertical_flip=True,\n",
    "        fill_mode= 'nearest')                         \n",
    "\n",
    "\n",
    "datagen.fit(X_train_2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_generator(datagen.flow(X_train_2, Y_train),\n",
    "                    steps_per_epoch=len(X_train_1) / 10, epochs=10) #validation_data=(X_val_2, Y_val),workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_k= classifier.predict(X_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "    \n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Convolution2D\n",
    "    from keras.layers import MaxPooling2D\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras.layers import GaussianNoise\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from keras.wrappers.scikit_learn import KerasClassifier\n",
    "    \n",
    "\n",
    "    classifier= Sequential()\n",
    "    classifier.add(Convolution2D(512, 3, 3 , input_shape= (32, 32, 3), activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    classifier.add(Convolution2D(1024, 3, 3, activation= 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "    classifier.add(Dropout(0.15))\n",
    "    classifier.add(Convolution2D(2048, 3, 3, activation= 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "    classifier.add(Dropout(0.10))\n",
    "    classifier.add(Flatten())\n",
    "    \n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(GaussianNoise(0.25))\n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim=256, activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim=1, activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer= opt , loss= 'hinge', metrics= ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier= KerasClassifier(build_fn= build_classifier)\n",
    "\n",
    "parameters= { 'batch_size' : [10, 16, 32],'epochs': [30, 100, 200],'optimizer': ['Adagrad', 'RMSprop', 'SGD', 'adam']}\n",
    "\n",
    "grid_search= GridSearchCV(estimator= classifier, param_grid= parameters, scoring='accuracy', cv=100)\n",
    "\n",
    "grid_search= grid_search.fit(X_train_1, Y_train)\n",
    "\n",
    "best_parameters= grid_search.best_params_\n",
    "\n",
    "best_accuracy= grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_svm= X_train_2.reshape(1200, 3072)\n",
    "X_val_svm= X_val_2.reshape(300, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vicky\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf= svm.LinearSVC()\n",
    "clf.fit(X_train_svm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict= clf.predict(X_val_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_val, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_val, predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
